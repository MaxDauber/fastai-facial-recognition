{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from fastai import *\n",
    "from fastai.vision import *\n",
    "import torch\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import cv2\n",
    "import dlib\n",
    "import subprocess\n",
    "import random\n",
    "import os\n",
    "bs=8\n",
    "torch.cuda.is_available()\n",
    "torch.cuda.set_device(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%reload_ext autoreload\n",
    "%autoreload 2\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Declaring path of dataset\n",
    "path_img = Path('/root/model_training/intern_images')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#function to create list of cv2-loaded images in a given directory\n",
    "def load_images_from_folder(folder):\n",
    "    images = []\n",
    "    for filename in os.listdir(folder):\n",
    "        img = cv2.imread(os.path.join(folder,filename),1)\n",
    "        if img is not None:\n",
    "            images.append(img)\n",
    "    return images\n",
    "\n",
    "#function to convert cv2-loaded image into RGB\n",
    "def convertToRGB(image):\n",
    "    return cv2.cvtColor(image, cv2.COLOR_BGR2RGB)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model to use to locate faces\n",
    "haar_cascade_face = cv2.CascadeClassifier('./data/haarcascade/haarcascade_frontalface_default.xml')\n",
    "\n",
    "for dirname, dirnames, filenames in os.walk('./intern_images'):\n",
    "    for subdirname in dirnames:\n",
    "        #print(os.path.join(dirname, subdirname))\n",
    "        imgs = load_images_from_folder(os.path.join(dirname, subdirname))\n",
    "        print('loaded images for '+ subdirname)\n",
    "        for img in imgs:\n",
    "            print(img.shape)\n",
    "            width = 720\n",
    "            height = 1080\n",
    "            # for if you want to preserve aspect ratio\n",
    "            # scale_percent = 25 # percent of original size\n",
    "            # width = int(img.shape[1] * scale_percent / 100)\n",
    "            # height = int(img.shape[0] * scale_percent / 100)\n",
    "            dim = (width, height)\n",
    "            # resize image\n",
    "            resized = cv2.resize(img, dim, interpolation = cv2.INTER_AREA)\n",
    "            faces = haar_cascade_face.detectMultiScale(resized, scaleFactor = 1.2, minNeighbors = 5)\n",
    "            for (x,y,w,h) in faces:\n",
    "                 cv2.rectangle(resized, (x, y), (x+w, y+h), (0, 255, 0), 2)\n",
    "            plt.imshow(convertToRGB(resized))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img_raw = cv2.imread(path_img+'max/max_001.JPG',1)\n",
    "type(img_raw)\n",
    "img_raw.shape\n",
    "plt.imshow(img_raw)\n",
    "cv2.imwrite(os.path.join(path , 'waka.jpg'), img)\n",
    "cv2.waitKey(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "## applying transforms\n",
    "tfms_list = [rotate(degrees=270, p=1),jitter(magnitude=(random.randrange(-3,3)/100), p=0.25), \n",
    "            contrast(scale=(0.5, 2.), p=0.5), brightness(change=(0.1, 0.9), p=0.5)]\n",
    "tfms_list = [rotate(degrees=270, p=1)]\n",
    "tfms = [tfms_list, tfms_list]\n",
    "\n",
    "## Loading data \n",
    "data = ImageDataBunch.from_folder(path=path_img, train='/', valid_pct=0.07, ds_tfms=tfms, bs=bs, size=(540,720))\n",
    "\n",
    "## Normalizing data based on ImageNet parameters\n",
    "data.normalize(imagenet_stats)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.show_batch(rows=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(data.classes)\n",
    "len(data.classes),data.c"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "face_detector = dlib.get_frontal_face_detector()\n",
    "for file_name in data.items:\n",
    "    img = dlib.load_rgb_image(str(file_name))\n",
    "    detected_faces = face_detector(img)\n",
    "    print(\"Found {} faces in the image file {}\".format(len(detected_faces), file_name))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_ex(): return open_image(path_img/'max/max_001.JPG')\n",
    "\n",
    "def plots_f(rows, cols, width, height, **kwargs):\n",
    "    [get_ex().apply_tfms(tfms[0], **kwargs).show(ax=ax) for i,ax in enumerate(plt.subplots(\n",
    "        rows,cols,figsize=(width,height))[1].flatten())]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "## To create a ResNET 50 with pretrained weights\n",
    "learn = cnn_learner(data, models.resnet50, metrics=accuracy)\n",
    "print(learn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "learn.fit_one_cycle(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Training results:  ' + str(learn.validate(learn.data.train_dl)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Validation results: ' + str(learn.validate(learn.data.valid_dl)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "preds,y,losses = learn.get_preds(with_loss=True)\n",
    "interp = ClassificationInterpretation(learn, preds, y, losses)\n",
    "\n",
    "interp = ClassificationInterpretation.from_learner(learn)\n",
    "interp.plot_top_losses(4, figsize=(5,5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "interp.plot_confusion_matrix(figsize=(5,5), dpi=60)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "learn.lr_find()\n",
    "learn.recorder.plot()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
